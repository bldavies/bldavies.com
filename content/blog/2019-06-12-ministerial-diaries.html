---
title: Reading the Ministerial Diaries
tags: [pdftools, tidytext, R]
---



<p>In December 2018, the New Zealand Government <a href="https://www.beehive.govt.nz/release/government-proactively-release-ministerial-diaries">announced</a> that its ministers “will for the first time release details of their internal and external meetings.”
The Government has since published these “ministerial diaries” as <a href="https://www.beehive.govt.nz/search?f%5B0%5D=content_type_facet%3Aministerial_diary&amp;f%5B1%5D=government_facet%3A6203&amp;f%5B2%5D=ministers%3A6205">a series of PDFs</a>.
In this post, I analyse the ministerial diary of <a href="https://www.beehive.govt.nz/minister/hon-david-parker">David Parker</a>, a <a href="https://www.odt.co.nz/news/election-2017/parker-emerges-pivotal-cabinet-minister">“pivotal cabinet minister”</a> who wears a range of politically and economically significant hats:</p>
<ul>
<li>Attorney-General;</li>
<li>Minister of Economic Development;</li>
<li>Minister for the Environment;</li>
<li>Minister of Trade and Export Growth;</li>
<li>Associate Minister of Finance.</li>
</ul>
<p>These roles, coupled with his scheduled activities for the 2018 calendar year being available in <a href="https://www.beehive.govt.nz/sites/default/files/2019-05/October%202017%20-%20December%202018_0.pdf">a single, consistently formatted table</a>, make Minister Parker’s diary (hereafter “the diary”) an interesting and relatively painless document to analyse.</p>
<div id="parsing-the-data" class="section level2">
<h2>Parsing the data</h2>
<p>I read the diary into R using the <code>pdf_data</code> function from <a href="https://cran.r-project.org/package=pdftools"><code>pdftools</code></a>:</p>
<pre class="r"><code>library(pdftools)

path &lt;- &quot;https://www.beehive.govt.nz/sites/default/files/2019-05/October%202017%20-%20December%202018_0.pdf&quot;
pages &lt;- pdf_data(path)</code></pre>
<p><code>pdf_data</code> scans each page for distinct words, encloses these words in <a href="https://en.wikipedia.org/wiki/Minimum_bounding_box">bounding boxes</a>, and stores the coordinates and content of each box as a list of tibbles.
For example, the diary’s first page contains the following data:</p>
<pre class="r"><code>library(dplyr)

pages[[1]]</code></pre>
<pre><code>## # A tibble: 336 x 6
##    width height     x     y space text    
##    &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt; &lt;chr&gt;   
##  1    46     20    72    75 TRUE  David   
##  2    52     20   122    75 TRUE  Parker  
##  3    42     20   179    75 TRUE  Diary   
##  4    77     20   226    75 FALSE Summary 
##  5    11     11    72   102 TRUE  26      
##  6    36     11    85   102 TRUE  October 
##  7    22     11   124   102 TRUE  2017    
##  8     3     11   149   102 TRUE  -       
##  9    11     11   155   102 TRUE  31      
## 10    46     11   168   102 TRUE  December
## # … with 326 more rows</code></pre>
<p>The <code>x</code> and <code>y</code> columns provide the horizontal and vertical displacement, in pixels, of each bounding box from the top-left corner of the page.
The left-most boxes sit 72 pixels from the left page boundary, allowing me to identify table rows by the cumulative number of boxes for which <code>x</code> equals 72.</p>
<pre class="r"><code>pages[[1]] %&gt;%
  arrange(y, x) %&gt;%
  mutate(row = cumsum(x == 72)) %&gt;%
  filter(cumsum(x == 72 &amp; text == &quot;Date&quot;) &gt; 0)  # Remove preamble</code></pre>
<pre><code>## # A tibble: 91 x 7
##    width height     x     y space text         row
##    &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt; &lt;chr&gt;      &lt;int&gt;
##  1    21     11    72   355 FALSE Date          14
##  2    46     11   149   355 TRUE  Scheduled     14
##  3    22     11   198   355 FALSE Time          14
##  4    37     11   235   355 FALSE Meeting       14
##  5    38     11   390   355 FALSE Location      14
##  6    21     11   504   355 FALSE With          14
##  7    39     11   630   355 FALSE Portfolio     14
##  8    53     11    72   382 FALSE 26/10/2017    15
##  9    25     11   149   382 TRUE  11:00         15
## 10     3     11   177   382 TRUE  -             15
## # … with 81 more rows</code></pre>
<p>The <code>x</code> values for which <code>row</code> equals 14 provide the left alignment points for the text in each of the diary’s six columns.
These points remain unchanged across all 84 pages, allowing me to identify rows and columns throughout the diary within a single pipe:</p>
<pre class="r"><code>library(tidyr)

# Define column names and left alignment points
columns &lt;- tibble(
  left_x = c(72, 149, 235, 390, 504, 630),
  name = c(&quot;date&quot;, &quot;scheduled_time&quot;, &quot;meeting&quot;, &quot;location&quot;, &quot;with&quot;, &quot;portfolio&quot;)
)

# Identify page numbers
for (i in 1 : length(pages)) pages[[i]]$page &lt;- i

# Process data
diary &lt;- bind_rows(pages) %&gt;%
  # Identify table rows
  arrange(page, y, x) %&gt;%
  mutate(row = cumsum(x == columns$left_x[1])) %&gt;%
  filter(cumsum(x == columns$left_x[1] &amp; text == &quot;Date&quot;) == 1) %&gt;%
  filter(row &gt; min(row)) %&gt;%  # Remove header row
  # Identify table columns
  mutate(column = sapply(x, function(x){max(which(columns$left_x &lt;= x))}),
         column = columns$name[column]) %&gt;%
  # Concatenate text within table cells
  group_by(row, column) %&gt;%
  summarise(text = paste(text, collapse = &quot; &quot;)) %&gt;%
  ungroup() %&gt;%
  # Clean data
  clean_data() %&gt;%
  # Convert to wide format
  mutate(column = factor(column, levels = columns$name)) %&gt;%
  spread(column, text) %&gt;%
  select(-row)</code></pre>
<p>I define the <code>clean_data</code> function in <a href="#appendix">the appendix</a> below.</p>
<p>The resulting tibble <code>diary</code> contains 1,553 rows, each of which describes a unique entry scheduled between October 2017 and December 2018.
I select entries scheduled during the 2018 calendar year:</p>
<pre class="r"><code>(data &lt;- filter(diary, grepl(&quot;2018&quot;, date)))</code></pre>
<pre><code>## # A tibble: 1,347 x 6
##    date   scheduled_time meeting         location    with       portfolio  
##    &lt;chr&gt;  &lt;chr&gt;          &lt;chr&gt;           &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;      
##  1 15/01… 10:00 - 11:00  Meeting with F… Beehive     Treasury … Associate …
##  2 15/01… 14:00 - 14:30  Meeting with M… Beehive     MFAT offi… Trade and …
##  3 15/01… 15:00 - 15:30  Meeting with M… Beehive     MBIE offi… Economic D…
##  4 16/01… 09:30 - 10:15  Meeting with E… Selwyn      Environme… Environment
##  5 16/01… 10:40 - 11:40  Meeting with N… Springston  Ngai Tahu… Environment
##  6 16/01… 12:00 - 12:30  Meeting with f… Canterbury  Farm owne… Environment
##  7 16/01… 12:40 - 13:40  Working Lunch … Canterbury  Te Waihor… Environment
##  8 16/01… 13:50 - 14:45  Meeting with f… Leeston     Farm owne… Environment
##  9 16/01… 16:30 - 17:30  Meeting with S… Middleton,… Syft Tech… Economic D…
## 10 17/01… 09:30 - 10:00  Meeting with C… Beehive     Cabinet O… All        
## # … with 1,337 more rows</code></pre>
<p>According to <a href="https://www.beehive.govt.nz/ministerial-diaries-full-disclaimer">the official disclaimer</a>, the diary excludes personal and party political meetings, along with details published elsewhere such as time spent in the House of Representatives.
Moreover, some details are withheld under various sections of <a href="http://legislation.govt.nz/act/public/1982/0156/latest/DLM64785.html">the Official Information Act</a>.
I assume that the remaining entries provide a representative sample of Minister Parker’s ministerial activities.</p>
</div>
<div id="analysing-word-frequencies" class="section level2">
<h2>Analysing word frequencies</h2>
<p>I analyse the frequency of words used in the <code>with</code> column of <code>data</code>.
These frequencies provide insight into Minister Parker’s interactions with different organisations.
I use the <code>unnest_tokens</code> function from <a href="https://cran.r-project.org/package=tidytext"><code>tidytext</code></a> to identify unique words and the <code>count</code> function from <code>dplyr</code> to count word frequencies.</p>
<pre class="r"><code>library(tidytext)

data %&gt;%
  unnest_tokens(word, with) %&gt;%
  anti_join(get_stopwords()) %&gt;%  # Remove stop words
  count(word, sort = TRUE)</code></pre>
<pre><code>## # A tibble: 674 x 2
##    word          n
##    &lt;chr&gt;     &lt;int&gt;
##  1 attending   290
##  2 officials   272
##  3 minister    198
##  4 ministers   108
##  5 mfe          89
##  6 mbie         82
##  7 jones        76
##  8 sage         58
##  9 twyford      56
## 10 mfat         53
## # … with 664 more rows</code></pre>
<p>The most frequent word, “attending,” reflects cabinet meetings, media briefings and other general ministerial duties.
The next most frequent word, “officials,” reflects Minister Parker’s meetings with the Ministry for the Environment (MfE), the Ministry of Business, Innovation and Employment (MBIE), and the Ministry of Foreign Affairs and Trade (MFAT), along with other government departments.
Both “minister” and “ministers” reflect meetings with Ministers <a href="https://www.beehive.govt.nz/minister/hon-shane-jones">Jones</a>, <a href="https://www.beehive.govt.nz/minister/hon-eugenie-sage">Sage</a>, <a href="https://www.beehive.govt.nz/minister/hon-phil-twyford">Twyford</a> and others.</p>
<div id="computing-tf-idf-scores" class="section level3">
<h3>Computing tf-idf scores</h3>
<p>Counting word frequencies across all portfolios masks portfolio-specific interactions.
I infer such interactions from the <a href="https://www.tidytextmining.com/tfidf.html"><em>term frequency-inverse document frequency</em></a> (tf-idf) scores of word-portfolio pairs.
I identify these pairs as follows.</p>
<pre class="r"><code>word_portfolio_pairs &lt;- data %&gt;%
  # Disambiguate portfolio names
  mutate(portfolio = gsub(&quot;Att.*?ral|AG&quot;, &quot;Attorney-General&quot;, portfolio)) %&gt;%
  # Split entries with multiple porfolios
  mutate(portfolio = gsub(&quot;[^[:alpha:] -]&quot;, &quot;&amp;&quot;, portfolio),
         portfolio = strsplit(portfolio, &quot;&amp;&quot;)) %&gt;%
  unnest() %&gt;%
  mutate(portfolio = trimws(portfolio)) %&gt;%
  # Identify word-portfolio pairs
  filter(!is.na(portfolio)) %&gt;%
  unnest_tokens(word, with) %&gt;%
  select(word, portfolio)</code></pre>
<p>tf-idf scores measure the “importance” of words in each document in a corpus.
The <em>term frequency</em></p>
<p><code>$$ \mathrm{tf}(w, d)=\frac{\text{Number of occurrences of word}\ w\ \text{in document}\ d}{\text{Number of words in document}\ d} $$</code></p>
<p>measures the rate at which word <code>$w$</code> occurs in a document <code>$d$</code>, while the <em>inverse document frequency</em></p>
<p><code>$$ \mathrm{idf}(w) = -\ln\left(\frac{\text{Number of documents containing word}\ w}{\text{Number of documents}}\right) $$</code></p>
<p>provides a normalisation factor that penalises ubiquitous words.
The tf-idf score</p>
<p><code>$$ \text{tf-idf}(w,d) = \mathrm{tf}(w, d) \cdot \mathrm{idf}(w) $$</code></p>
<p>thus measures the prevalence of word <code>$w$</code> in document <code>$d$</code>, normalised by that word’s prevalence in other documents.
I interpret the set of entries associated with each portfolio as a document and use the <code>bind_tf_idf</code> function from <code>tidytext</code> to compute word-portfolio tf-idf scores:</p>
<pre class="r"><code>word_portfolio_pairs %&gt;%
  count(word, portfolio) %&gt;%
  bind_tf_idf(word, portfolio, n)</code></pre>
<pre><code>## # A tibble: 1,066 x 6
##    word        portfolio                   n       tf   idf   tf_idf
##    &lt;chr&gt;       &lt;chr&gt;                   &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;
##  1 a           Associate Finance           1 0.00285  0.693 0.00197 
##  2 a           Environment                 1 0.000739 0.693 0.000512
##  3 a           Trade and Export Growth     2 0.00277  0.693 0.00192 
##  4 accelerator Economic Development        1 0.00137  1.79  0.00245 
##  5 acting      Attorney-General            1 0.00215  1.79  0.00385 
##  6 action      Trade and Export Growth     1 0.00139  1.79  0.00248 
##  7 adrian      Economic Development        1 0.00137  1.79  0.00245 
##  8 advisory    Economic Development        2 0.00273  0.693 0.00189 
##  9 advisory    Environment                 1 0.000739 0.693 0.000512
## 10 advisory    Trade and Export Growth     1 0.00139  0.693 0.000960
## # … with 1,056 more rows</code></pre>
<p>The <code>idf</code> column identifies both language-specific stop words (e.g., “a”) and context-specific stop words (e.g., “advisory”) that are common across portfolios.</p>
<p>The chart below presents the highest tf-idf words for each portfolio.
These words reveal organisations (e.g., the Parliamentary Counsel Office) and individuals (e.g., <a href="https://ec.europa.eu/commission/commissioners/2014-2019/malmstrom_en">Cecilia Malmström</a>) that are missing from the diary-wide word frequencies computed above.</p>
<p><img src="/blog/2019-06-12-ministerial-diaries_files/figure-html/highest-tf-idf-1.svg" width="768" /></p>
<p>The chart also reveals which interactions correspond to which portfolios.
For example, Minister Parker’s frequent interactions with MBIE officials appear to be most associated with the Economic Development portfolio, while his interactions with Minister Sage appear to involve both the Environment and Associate Finance portfolios.
(<a href="https://www.greens.org.nz/sites/default/files/Eugenie%20Sage%27s%20July-Sept%202018%20Diary.pdf">Minister Sage’s diary</a> suggests that such cross-portfolio interactions relate to the Overseas Investment Office, for which Ministers Parker and Sage are jointly responsible.)</p>
</div>
</div>
<div id="acknowledgements" class="section level2">
<h2>Acknowledgements</h2>
<p><a href="https://ropensci.org/technotes/2018/12/14/pdftools-20/">The pdftools 2.0 release notes</a> helped me interpret <code>pdf_data</code>’s output.
<a href="https://juliasilge.com">Julia Silge</a> and <a href="http://varianceexplained.org">David Robinson</a>’s book <a href="https://www.tidytextmining.com"><em>Text Mining with R</em></a> provided useful background reading, especially <a href="https://www.tidytextmining.com/tfidf.html">the chapter on tf-idf scores</a>.</p>
</div>
<div id="appendix" class="section level2">
<h2>Appendix</h2>
<div id="source-code-for-clean_data" class="section level3">
<h3>Source code for <code>clean_data()</code></h3>
<pre class="r"><code>clean_data &lt;- function (df) {
  df %&gt;%
    # Replace non-ASCII characters with ASCII equivalents
    mutate(text = iconv(text, &quot;&quot;, &quot;ASCII&quot;, sub = &quot;byte&quot;),
           text = gsub(&quot;&lt;c3&gt;&lt;a7&gt;&quot;, &quot;c&quot;, text),
           text = gsub(&quot;&lt;c3&gt;&lt;a9&gt;&quot;, &quot;e&quot;, text),
           text = gsub(&quot;&lt;c3&gt;&lt;b1&gt;&quot;, &quot;n&quot;, text),
           text = gsub(&quot;&lt;c4&gt;&lt;81&gt;&quot;, &quot;a&quot;, text),
           text = gsub(&quot;&lt;c5&gt;&lt;ab&gt;&quot;, &quot;u&quot;, text),
           text = gsub(&quot;&lt;e2&gt;&lt;80&gt;&lt;93&gt;&quot;, &quot;-&quot;, text),
           text = gsub(&quot;&lt;e2&gt;&lt;80&gt;&lt;99&gt;&quot;, &quot;&#39;&quot;, text),
           text = gsub(&quot;&lt;e2&gt;&lt;80&gt;&lt;9c&gt;|&lt;e2&gt;&lt;80&gt;&lt;9d&gt;&quot;, &quot;\&quot;&quot;, text)) %&gt;%
    # Fix linebroken data ranges
    spread(column, text) %&gt;%
    mutate(split_date = is.na(scheduled_time) &amp; grepl(&quot;-&quot;, paste(date, lag(date))),
           row = cumsum(!split_date)) %&gt;%
    select(-split_date) %&gt;%
    gather(column, text, -row) %&gt;%
    group_by(row, column) %&gt;%
    summarise(text = gsub(&quot;NA&quot;, &quot;&quot;, paste(text, collapse = &quot; &quot;))) %&gt;%
    ungroup() %&gt;%
    mutate(text = trimws(text),
           text = ifelse(text == &quot;&quot;, NA, text)) %&gt;%
    # Fix transcription errors
    mutate(text = gsub(&quot;Minster&quot;, &quot;Minister&quot;, text),
           text = ifelse(column == &quot;portfolio&quot; &amp; text == &quot;Minister Little&quot;, &quot;Attorney-General&quot;, text))
}</code></pre>
</div>
</div>
