---
title: Accessing the Strava API with R
tags: [Strava, API, fitness, running, cycling, R]
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(dev = "svg",
                      echo = TRUE,
                      fig.ext = "svg",
                      message = FALSE,
                      warning = FALSE)

library(dplyr)
library(ggplot2)
library(ggridges)
library(googleway)
library(httr)
library(jsonlite)
library(lubridate)
library(scales)
library(tidyr)
library(yaml)

DATA_DIR <- "../../data/strava-api-access/"

credentials <- read_yaml(paste0(DATA_DIR, "credentials.yaml"))
```

[Strava](https://www.strava.com/) is an online platform for storing and sharing fitness data.
Strava [provides an API](https://developers.strava.com) for accessing such data at the activity (e.g., run or cycle) level.
In this post, I explain how to extract data from the Strava API using R, and I analyse my running and cycling data from 2018.

## Setup and authentication

Strava uses [OAuth 2.0](https://oauth.net/2/) to authorise access to the API data.
The first step to becoming authorised is to register for access on [Strava's API settings page](https://www.strava.com/settings/api/).
I put "localhost" in the "Authorization Callback Domain" field.
Upon completing the registration form, the page provides two important values: an integer client ID and an alpha-numeric client secret.
I store these values in `credentials.yaml`, which I structure as

```yaml
client_id: xxxxxxxxx
secret: xxxxxxxxx
```

and import into R using the `read_yaml` function from the [`yaml`](https://cran.r-project.org/package=yaml) package.

Next, I create an OAuth application for interacting with the API and an endpoint through which to send authentication requests.
I use the `oauth_app` and `oauth_endpoint` functions from [`httr`](https://cran.r-project.org/package=httr):

```{r, eval = FALSE}
library(httr)

app <- oauth_app("strava", credentials$client_id, credentials$secret)
endpoint <- oauth_endpoint(
  request = NULL,
  authorize = "https://www.strava.com/oauth/authorize",
  access = "https://www.strava.com/oauth/token"
)
```

Finally, I create an OAuth access token to send the authentication request to my Strava account.
This token encapsulates the application and endpoint defined above.
Running

```{r, eval = FALSE}
token <- oauth2.0_token(endpoint, app, as_header = FALSE, cache = FALSE)
```

opens a browser window at a web page for accepting the authentication request.
Doing so redirects me to the callback domain ("localhost") and prints a confirmation message:

> Authentication complete. Please close this page and return to R.

## Extracting the data

After authenticating with Strava, I use a sequence of HTTP requests to extract activity data from the API.
The API returns multiple pages of data, each containing up to 200 activities.
I use a while loop to iterate over pages, using the `fromJSON` function from [`jsonlite`](https://cran.r-project.org/package=jsonlite) to parse the extracted data:

```{r, eval = FALSE}
library(jsonlite)

data_list <- list()
i <- 1
done <- FALSE
while (!done) {
  req <- GET(
    url = "https://www.strava.com/api/v3/athlete/activities",
    config = token,
    query = list(per_page = 200, page = i)
  )
  data_list[[i]] <- fromJSON(content(req, as = "text"), flatten = TRUE)
  if (length(content(req)) < 200) {
    done <- TRUE
  } else {
    i <- i + 1
  }
}
```

Finally, I use the `rbind_pages` function from `jsonlite` to collate the activity data into a single data frame:

```{r, eval = FALSE}
data <- rbind_pages(data_list)
```

```{r save-cache, eval = FALSE, echo = FALSE}
saveRDS(data, paste0(DATA_DIR, "cache.rds"))
```

```{r load-cache, eval = TRUE, echo = FALSE}
data <- readRDS(paste0(DATA_DIR, "cache.rds"))
```

## Analysing the data

The Strava API provides a wealth of data to analyse.
Running

```{r, eval = FALSE}
names(data)
```

prints the variables included in `data`, such as distance, moving time, elevation gain, and starting latitude and longitude coordinates.
These data reveal patterns of fitness effort.
For example, the bar chart below plots my total distance run and cycled during each month of 2018.
I ran less during New Zealand's winter months: June--August.
With more years of data, I could quantify my sensitivity to cold temperatures by identifying the seasonal component of my monthly distance series.

```{r monthly-distances, echo = FALSE, fig.width = 8, fig.height = 4.5}
data %>%
  filter(type %in% c("Run", "Ride"),
         year(start_date_local) == 2018) %>%
  mutate(type = replace(type, type == "Run", "Running"),
         type = replace(type, type == "Ride", "Cycling"),
         month = floor_date(as_datetime(start_date_local), "month")) %>%
  group_by(month, type) %>%
  summarise(distance = sum(distance) / 1000) %>%
  ungroup() %>%
  ggplot(aes(month, distance, fill = type)) +
  geom_bar(stat = "identity") +
  labs(x = NULL,
       y = NULL,
       title = "Kilometres run and cycled during each month of 2018",
       fill = NULL) +
  scale_fill_brewer(palette = "Set1") +
  scale_x_datetime(breaks = date_breaks("month"),
                   expand = c(0, 0),
                   label = date_format("%b")) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_minimal() +
  theme(legend.position = "bottom",
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        plot.title = element_text(face = "bold", hjust = 0.5, margin = margin(b = 10), size = 16))
```

The temporal data provided by the API indicate the times of day at which athletes are most active.
For example, the density plots below show the distribution of my running activity for each weekday during 2018.
I ran mostly during lunch breaks or in the evenings on work days, and around midday on weekends.

```{r active-time, echo = FALSE, fig.width = 8, fig.height = 4.5}
boundaries <- data %>%
  filter(type == "Run",
         year(start_date_local) == 2018) %>%
  group_by(id) %>%
  summarise(start = as_datetime(start_date_local),
            end = start + seconds(elapsed_time),
            weekday = wday(start, week_start = 1)) %>%
  ungroup() %>%
  mutate(start = floor_date(start, "minute"),
         end = floor_date(end, "minute")) %>%
  gather(boundary, time, start, end) %>%
  mutate(boundary = factor(boundary, levels = c("start", "end")))
tibble(time = seq(min(boundaries$time), max(boundaries$time), by = 60)) %>%
  left_join(boundaries) %>%
  mutate(active = boundary == "start") %>%  # Exclude last partial minute
  fill(id, weekday, active) %>%  # Fill in active minutes from start to end
  filter(active) %>%
  mutate(date = as_date(time),
         time = time - months(month(date) - 1) - days(day(date) - 1)) %>%  # Isolate time variation
  ggplot(aes(time, factor(-weekday))) +
  geom_density_ridges() +
  coord_cartesian(clip = "off") +
  labs(x = NULL,
       y = NULL,
       title = "Distribution of active running time by weekday during 2018") +
  scale_x_datetime(date_labels = "%I:%M %p",
                   expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0),
                   labels = c("Sun", "Sat", "Fri", "Thu", "Wed", "Tue", "Mon")) +
  theme_minimal() +
  theme(panel.grid.minor.x = element_blank(),
        plot.title = element_text(face = "bold", hjust = 0.5, margin = margin(b = 10), size = 16))
```

The Strava API also provides spatial data on running and cycling routes.
Each activity is associated with an [encoded polyline](https://developers.google.com/maps/documentation/utilities/polylinealgorithm), which stores the geographic coordinates of points along each route.
Plotting these polylines reveals a map of where athletes travel during their runs and cycles.
For example, the image below maps my Wellington running routes from 2018.
These routes include coastal areas, such as Petone Beach in the northeast, and inland areas, such as the Zealandia fenceline in the southwest.

```{r wellington-routes, echo = FALSE, fig.width = 8, fig.height = 4.5}
wellington_data <- data %>%
  filter(type == "Run",
         year(start_date_local) == 2018,
         start_longitude > 174)
polylines_list <- list()
for (i in 1 : nrow(wellington_data)) {
  polylines_list[[i]] <- decode_pl(wellington_data$map.summary_polyline[i])
  polylines_list[[i]]$id <- wellington_data$id[i]
}
do.call(rbind, polylines_list) %>%
  ggplot(aes(lon, lat, group = id)) +
  geom_path() +
  labs(title = "Map of Wellington running routes from 2018") +
  coord_fixed() +
  theme_minimal() +
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(face = "bold", hjust = 0.5, margin = margin(b = 10), size = 16))
```

## Acknowledgements

This post is informed by several online resources.
[Mark Aberdour's blog post](http://www.open-thoughts.com/2017/01/the-quantified-cyclist-analysing-strava-data-using-r/) helped me understand the process for authenticating with Strava.
Reading [the `rStrava` package's source code](https://github.com/fawda123/rStrava) helped me understand how to extract data from the Strava API.
I got the idea for plotting active running time distributions from [this GitHub repository](https://github.com/marcusvolz/strava).
